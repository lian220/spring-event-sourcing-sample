INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-a94b71e8-8c4a-4dfe-af28-6feb10822b23 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 15:46:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 15:46:45[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 15:46:45[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 15:46:45[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 15:46:47[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 34064 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 15:46:47[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 56 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 180 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:46:48[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 15:46:49[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 15:46:49[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 15:46:49[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 15:46:49[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 15:46:49[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 15:46:49[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2599 ms
INFO  23-06-13 15:46:50[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 15:46:50[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 15:46:50[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 15:46:50[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 15:46:50[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 15:46:50[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 15:46:51[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 15:46:51[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 15:46:52[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 15:46:53[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 15:46:54[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 15:46:54[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 15:46:54[main] [AppInfoParser:121] - Kafka startTimeMs: 1686638814077
INFO  23-06-13 15:46:54[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 15:46:54[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 15:46:54[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 15:46:54[main] [ApiApplication:61] - Started ApiApplication in 8.067 seconds (JVM running for 8.896)
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=247, memberId='consumer-foo-1-f81b8ffb-4db2-406d-9598-b60436225257', protocol='range'}
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 247: {consumer-foo-1-f81b8ffb-4db2-406d-9598-b60436225257=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=247, memberId='consumer-foo-1-f81b8ffb-4db2-406d-9598-b60436225257', protocol='range'}
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 15:46:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-f81b8ffb-4db2-406d-9598-b60436225257 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 15:47:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 15:47:27[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 15:47:27[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 15:47:27[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 15:47:34[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 1172 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 15:47:34[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 43 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 119 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 15:47:35[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 25 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 15:47:36[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 15:47:36[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 15:47:36[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 15:47:36[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 15:47:37[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 15:47:37[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2543 ms
INFO  23-06-13 15:47:37[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 15:47:37[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 15:47:37[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 15:47:38[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 15:47:38[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 15:47:38[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 15:47:38[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 15:47:38[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 15:47:40[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 15:47:42[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 15:47:42[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 15:47:42[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 15:47:42[main] [AppInfoParser:121] - Kafka startTimeMs: 1686638862157
INFO  23-06-13 15:47:42[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 15:47:42[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 15:47:42[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 15:47:43[main] [ApiApplication:61] - Started ApiApplication in 8.623 seconds (JVM running for 9.389)
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=249, memberId='consumer-foo-1-6d208f72-0203-487f-a3de-52d3cbf99c6d', protocol='range'}
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 249: {consumer-foo-1-6d208f72-0203-487f-a3de-52d3cbf99c6d=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=249, memberId='consumer-foo-1-6d208f72-0203-487f-a3de-52d3cbf99c6d', protocol='range'}
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 15:47:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 15:56:09[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 15:56:09[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 15:56:09[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 2 ms
INFO  23-06-13 15:56:29[http-nio-8090-exec-2] [ExceptHandler:31] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 15:56:31[http-nio-8090-exec-3] [ExceptHandler:31] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 16:07:32[http-nio-8090-exec-5] [ExceptHandler:31] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-6d208f72-0203-487f-a3de-52d3cbf99c6d sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 16:07:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 16:07:35[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 16:07:35[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 16:07:35[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 16:07:39[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 19280 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 16:07:39[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 38 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 129 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:07:40[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 18 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 16:07:41[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 16:07:41[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:07:41[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 16:07:41[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 16:07:42[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 16:07:42[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2468 ms
INFO  23-06-13 16:07:42[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 16:07:42[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 16:07:42[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 16:07:42[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 16:07:42[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 16:07:42[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 16:07:43[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 16:07:43[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 16:07:44[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
WARN  23-06-13 16:07:45[main] [AnnotationConfigServletWebServerApplicationContext:591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'handlerExceptionResolver' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.web.servlet.HandlerExceptionResolver]: Factory method 'handlerExceptionResolver' threw exception; nested exception is java.lang.IllegalStateException: Ambiguous @ExceptionHandler method mapped for [class org.springframework.web.servlet.NoHandlerFoundException]: {protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(org.springframework.web.servlet.NoHandlerFoundException), protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(java.lang.IllegalStateException)}
INFO  23-06-13 16:07:45[main] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 16:07:45[main] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 16:07:45[main] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 16:07:45[main] [StandardService:173] - Stopping service [Tomcat]
INFO  23-06-13 16:07:45[main] [ConditionEvaluationReportLoggingListener:136] - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
ERROR 23-06-13 16:07:45[main] [SpringApplication:821] - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'handlerExceptionResolver' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.web.servlet.HandlerExceptionResolver]: Factory method 'handlerExceptionResolver' threw exception; nested exception is java.lang.IllegalStateException: Ambiguous @ExceptionHandler method mapped for [class org.springframework.web.servlet.NoHandlerFoundException]: {protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(org.springframework.web.servlet.NoHandlerFoundException), protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(java.lang.IllegalStateException)}
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:658)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:638)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1352)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1195)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292)
	at web.api.ApiApplication.main(ApiApplication.java:12)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.web.servlet.HandlerExceptionResolver]: Factory method 'handlerExceptionResolver' threw exception; nested exception is java.lang.IllegalStateException: Ambiguous @ExceptionHandler method mapped for [class org.springframework.web.servlet.NoHandlerFoundException]: {protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(org.springframework.web.servlet.NoHandlerFoundException), protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(java.lang.IllegalStateException)}
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	... 19 common frames omitted
Caused by: java.lang.IllegalStateException: Ambiguous @ExceptionHandler method mapped for [class org.springframework.web.servlet.NoHandlerFoundException]: {protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(org.springframework.web.servlet.NoHandlerFoundException), protected org.springframework.http.ResponseEntity web.api.exception.ExceptHandler.noHandlerFoundException(java.lang.IllegalStateException)}
	at org.springframework.web.method.annotation.ExceptionHandlerMethodResolver.addExceptionMapping(ExceptionHandlerMethodResolver.java:114)
	at org.springframework.web.method.annotation.ExceptionHandlerMethodResolver.<init>(ExceptionHandlerMethodResolver.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.initExceptionHandlerAdviceCache(ExceptionHandlerExceptionResolver.java:291)
	at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.afterPropertiesSet(ExceptionHandlerExceptionResolver.java:268)
	at org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport.addDefaultHandlerExceptionResolvers(WebMvcConfigurationSupport.java:1090)
	at org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport.handlerExceptionResolver(WebMvcConfigurationSupport.java:1032)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
	... 20 common frames omitted
INFO  23-06-13 16:08:32[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 34520 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 16:08:32[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 39 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 101 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:08:33[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 16:08:34[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 16:08:34[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:08:34[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 16:08:34[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 16:08:34[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 16:08:34[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2330 ms
INFO  23-06-13 16:08:35[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 16:08:35[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 16:08:35[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 16:08:35[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 16:08:35[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 16:08:35[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 16:08:36[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 16:08:36[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 16:08:37[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 16:08:39[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 16:08:39[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 16:08:39[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 16:08:39[main] [AppInfoParser:121] - Kafka startTimeMs: 1686640119373
INFO  23-06-13 16:08:39[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 16:08:39[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:08:39[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 16:08:40[main] [ApiApplication:61] - Started ApiApplication in 8.088 seconds (JVM running for 8.839)
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=251, memberId='consumer-foo-1-2c8f7674-cbbf-415d-85cc-cc0fd838067b', protocol='range'}
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 251: {consumer-foo-1-2c8f7674-cbbf-415d-85cc-cc0fd838067b=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=251, memberId='consumer-foo-1-2c8f7674-cbbf-415d-85cc-cc0fd838067b', protocol='range'}
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:08:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:12:06[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 16:12:06[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 16:12:06[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 16:12:06[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-2c8f7674-cbbf-415d-85cc-cc0fd838067b sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 16:39:04[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 16:39:04[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 16:39:04[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 16:39:04[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 16:39:06[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 41600 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 16:39:06[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 48 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 114 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:39:07[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 16:39:08[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 16:39:08[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:39:08[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 16:39:08[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 16:39:08[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 16:39:08[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2587 ms
INFO  23-06-13 16:39:09[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 16:39:09[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 16:39:09[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 16:39:09[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 16:39:09[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 16:39:09[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 16:39:10[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 16:39:10[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 16:39:11[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 16:39:13[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 16:39:13[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 16:39:13[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 16:39:13[main] [AppInfoParser:121] - Kafka startTimeMs: 1686641953716
INFO  23-06-13 16:39:13[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 16:39:13[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:39:13[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 16:39:14[main] [ApiApplication:61] - Started ApiApplication in 8.614 seconds (JVM running for 9.456)
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=253, memberId='consumer-foo-1-8079ac98-bd8e-455b-b450-e436e681a1c2', protocol='range'}
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 253: {consumer-foo-1-8079ac98-bd8e-455b-b450-e436e681a1c2=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=253, memberId='consumer-foo-1-8079ac98-bd8e-455b-b450-e436e681a1c2', protocol='range'}
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:39:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:48:08[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 16:48:08[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 16:48:08[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 16:48:16[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = Aggregate에 identifier를 argument로 받는 생성자가 없음
INFO  23-06-13 16:48:35[http-nio-8090-exec-8] [ExceptHandler:43] - ExceptHandler.commonException = Aggregate에 identifier를 argument로 받는 생성자가 없음
INFO  23-06-13 16:49:23[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 16:49:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:49:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=253, memberId='consumer-foo-1-8079ac98-bd8e-455b-b450-e436e681a1c2', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 16:49:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 16:49:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 16:49:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:49:35[http-nio-8090-exec-9] [ExceptHandler:43] - ExceptHandler.commonException = Aggregate에 identifier를 argument로 받는 생성자가 없음
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1127] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with stale Generation{generationId=253, memberId='consumer-foo-1-8079ac98-bd8e-455b-b450-e436e681a1c2', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, ignoring the error
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=255, memberId='consumer-foo-1-51144a24-1387-49f0-bd47-b21b662e4903', protocol='range'}
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 255: {consumer-foo-1-51144a24-1387-49f0-bd47-b21b662e4903=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=255, memberId='consumer-foo-1-51144a24-1387-49f0-bd47-b21b662e4903', protocol='range'}
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:49:35[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:49:45[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Aggregate에 identifier를 argument로 받는 생성자가 없음
WARN  23-06-13 16:52:51[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=3m28s538ms41µs200ns).
INFO  23-06-13 16:52:51[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 16:52:51[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Aggregate에 identifier를 argument로 받는 생성자가 없음
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [FetchSessionHandler:481] - [Consumer clientId=consumer-foo-1, groupId=foo] Error sending fetch request (sessionId=214428773, epoch=1188) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 16:52:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 16:52:51[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 16:52:51[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 16:52:51[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 16:52:53[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 39868 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 16:52:53[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 40 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 142 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:52:54[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 16:52:56[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 16:52:56[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:52:56[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 16:52:56[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 16:52:56[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 16:52:56[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2724 ms
INFO  23-06-13 16:52:56[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 16:52:56[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 16:52:57[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 16:52:57[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 16:52:57[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 16:52:57[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 16:52:58[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 16:52:58[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 16:52:59[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 16:53:01[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 16:53:01[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 16:53:01[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 16:53:01[main] [AppInfoParser:121] - Kafka startTimeMs: 1686642781268
INFO  23-06-13 16:53:01[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 16:53:01[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:53:01[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 16:53:02[main] [ApiApplication:61] - Started ApiApplication in 8.793 seconds (JVM running for 9.799)
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=257, memberId='consumer-foo-1-cad5fd14-6889-46ca-87ba-88923efdd8be', protocol='range'}
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 257: {consumer-foo-1-cad5fd14-6889-46ca-87ba-88923efdd8be=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=257, memberId='consumer-foo-1-cad5fd14-6889-46ca-87ba-88923efdd8be', protocol='range'}
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:53:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:53:05[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 16:53:05[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 16:53:05[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
WARN  23-06-13 16:54:25[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m28s308ms516µs699ns).
INFO  23-06-13 16:54:25[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 16:54:26[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=257, memberId='consumer-foo-1-cad5fd14-6889-46ca-87ba-88923efdd8be', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=259, memberId='consumer-foo-1-dad106bc-12f2-4f6c-8219-d12bb8a7dab4', protocol='range'}
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 259: {consumer-foo-1-dad106bc-12f2-4f6c-8219-d12bb8a7dab4=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=259, memberId='consumer-foo-1-dad106bc-12f2-4f6c-8219-d12bb8a7dab4', protocol='range'}
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:54:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:54:55[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:54:56[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=259, memberId='consumer-foo-1-dad106bc-12f2-4f6c-8219-d12bb8a7dab4', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=261, memberId='consumer-foo-1-dbc7b387-bb51-4d3e-8f76-c9865edd32b4', protocol='range'}
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 261: {consumer-foo-1-dbc7b387-bb51-4d3e-8f76-c9865edd32b4=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=261, memberId='consumer-foo-1-dbc7b387-bb51-4d3e-8f76-c9865edd32b4', protocol='range'}
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:54:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-dbc7b387-bb51-4d3e-8f76-c9865edd32b4 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 16:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 16:55:55[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 16:55:55[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 16:55:55[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 16:55:57[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 25192 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 16:55:57[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 43 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 16:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 101 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 16:55:58[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 16 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 16:55:59[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 16:55:59[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:55:59[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 16:55:59[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 16:55:59[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 16:55:59[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2469 ms
INFO  23-06-13 16:55:59[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 16:55:59[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 16:56:00[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 16:56:00[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 16:56:00[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 16:56:00[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 16:56:01[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 16:56:01[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 16:56:02[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 16:56:04[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 16:56:04[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 16:56:04[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 16:56:04[main] [AppInfoParser:121] - Kafka startTimeMs: 1686642964330
INFO  23-06-13 16:56:04[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 16:56:04[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 16:56:04[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 16:56:05[main] [ApiApplication:61] - Started ApiApplication in 8.59 seconds (JVM running for 9.368)
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=263, memberId='consumer-foo-1-8306dd05-4820-4b77-9bd0-8aa9ddbd8646', protocol='range'}
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 263: {consumer-foo-1-8306dd05-4820-4b77-9bd0-8aa9ddbd8646=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=263, memberId='consumer-foo-1-8306dd05-4820-4b77-9bd0-8aa9ddbd8646', protocol='range'}
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 16:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 16:56:51[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 16:56:51[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 16:56:51[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
WARN  23-06-13 16:59:56[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=3m26s201ms901µs500ns).
INFO  23-06-13 16:59:56[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:00:08[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 30732 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:00:08[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 50 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 108 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:00:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:00:10[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:00:10[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:00:10[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:00:10[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:00:11[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:00:11[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2236 ms
INFO  23-06-13 17:00:11[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:00:11[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:00:11[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:00:11[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:00:11[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:00:11[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:00:12[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:00:12[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:00:13[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:00:15[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:00:15[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:00:15[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:00:15[main] [AppInfoParser:121] - Kafka startTimeMs: 1686643215681
INFO  23-06-13 17:00:15[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:00:15[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:00:15[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:00:16[main] [ApiApplication:61] - Started ApiApplication in 8.203 seconds (JVM running for 9.024)
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=265, memberId='consumer-foo-1-b3febb2f-8bf6-4bb2-b381-97ee8c1402ba', protocol='range'}
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 265: {consumer-foo-1-b3febb2f-8bf6-4bb2-b381-97ee8c1402ba=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=265, memberId='consumer-foo-1-b3febb2f-8bf6-4bb2-b381-97ee8c1402ba', protocol='range'}
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:00:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:00:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:00:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:00:28[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:00:28[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:00:28[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:00:31[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 17:00:33[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 17:03:33[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:03:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=265, memberId='consumer-foo-1-b3febb2f-8bf6-4bb2-b381-97ee8c1402ba', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:03:34[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=267, memberId='consumer-foo-1-6d04cb77-5065-4076-9f0e-e11921f64e10', protocol='range'}
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 267: {consumer-foo-1-6d04cb77-5065-4076-9f0e-e11921f64e10=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=267, memberId='consumer-foo-1-6d04cb77-5065-4076-9f0e-e11921f64e10', protocol='range'}
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:03:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:23:05[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=19m52s10ms918µs400ns).
INFO  23-06-13 17:23:05[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
INFO  23-06-13 17:23:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:23:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=267, memberId='consumer-foo-1-6d04cb77-5065-4076-9f0e-e11921f64e10', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:23:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:23:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:23:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:23:10[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:23:10[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:23:11[http-nio-8090-exec-4] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=269, memberId='consumer-foo-1-d7c402c8-f139-4e02-a657-34a32a5b4911', protocol='range'}
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 269: {consumer-foo-1-d7c402c8-f139-4e02-a657-34a32a5b4911=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=269, memberId='consumer-foo-1-d7c402c8-f139-4e02-a657-34a32a5b4911', protocol='range'}
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:23:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:24:20[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=45s206ms748µs800ns).
INFO  23-06-13 17:24:20[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:24:20[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:24:20[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:24:20[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:24:20[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:24:20[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:24:22[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 42164 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:24:22[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 36 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 101 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:24:23[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 15 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:24:24[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:24:24[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:24:24[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:24:24[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:24:24[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:24:24[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2470 ms
INFO  23-06-13 17:24:25[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:24:25[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:24:25[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:24:25[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:24:25[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:24:25[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:24:26[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:24:26[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:24:27[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:24:29[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:24:29[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:24:29[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:24:29[main] [AppInfoParser:121] - Kafka startTimeMs: 1686644669240
INFO  23-06-13 17:24:29[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:24:29[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:24:29[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:24:29[main] [ApiApplication:61] - Started ApiApplication in 8.022 seconds (JVM running for 8.775)
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=271, memberId='consumer-foo-1-c97952a4-14c1-40ad-8998-4154aae1ff2f', protocol='range'}
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 271: {consumer-foo-1-c97952a4-14c1-40ad-8998-4154aae1ff2f=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=271, memberId='consumer-foo-1-c97952a4-14c1-40ad-8998-4154aae1ff2f', protocol='range'}
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:24:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:25:03[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:25:03[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:25:03[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 0 ms
INFO  23-06-13 17:25:13[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-c97952a4-14c1-40ad-8998-4154aae1ff2f sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:25:56[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:25:56[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:25:56[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:25:56[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:26:00[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 41752 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:26:00[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 51 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 115 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:26:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 16 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:26:02[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:26:02[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:26:02[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:26:02[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:26:03[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:26:03[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2427 ms
INFO  23-06-13 17:26:03[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:26:03[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:26:03[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:26:03[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:26:03[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:26:03[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:26:04[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:26:04[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:26:05[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:26:07[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:26:07[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:26:07[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:26:07[main] [AppInfoParser:121] - Kafka startTimeMs: 1686644767952
INFO  23-06-13 17:26:07[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:26:07[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:26:08[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:26:08[main] [ApiApplication:61] - Started ApiApplication in 8.749 seconds (JVM running for 9.567)
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=273, memberId='consumer-foo-1-bb355c24-89da-4762-ae17-6cd55b6936fd', protocol='range'}
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 273: {consumer-foo-1-bb355c24-89da-4762-ae17-6cd55b6936fd=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=273, memberId='consumer-foo-1-bb355c24-89da-4762-ae17-6cd55b6936fd', protocol='range'}
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:26:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:26:42[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:26:42[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:26:42[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
WARN  23-06-13 17:28:09[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m35s96ms627µs101ns).
INFO  23-06-13 17:28:09[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:28:09[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=273, memberId='consumer-foo-1-bb355c24-89da-4762-ae17-6cd55b6936fd', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=275, memberId='consumer-foo-1-914bf85f-5730-4d58-bc92-60fbf4eb97c4', protocol='range'}
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 275: {consumer-foo-1-914bf85f-5730-4d58-bc92-60fbf4eb97c4=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=275, memberId='consumer-foo-1-914bf85f-5730-4d58-bc92-60fbf4eb97c4', protocol='range'}
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-914bf85f-5730-4d58-bc92-60fbf4eb97c4 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:28:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:28:09[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:28:09[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:28:09[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:28:10[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 19068 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:28:10[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 46 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 131 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:28:11[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 18 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:28:12[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:28:12[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:28:12[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:28:12[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:28:13[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:28:13[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2511 ms
INFO  23-06-13 17:28:13[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:28:13[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:28:13[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:28:13[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:28:14[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:28:14[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:28:14[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:28:14[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:28:16[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:28:17[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:28:18[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:28:18[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:28:18[main] [AppInfoParser:121] - Kafka startTimeMs: 1686644898074
INFO  23-06-13 17:28:18[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:28:18[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:28:18[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:28:18[main] [ApiApplication:61] - Started ApiApplication in 8.501 seconds (JVM running for 9.326)
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=277, memberId='consumer-foo-1-616e15eb-d512-4072-8323-930dcfd97dbd', protocol='range'}
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 277: {consumer-foo-1-616e15eb-d512-4072-8323-930dcfd97dbd=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=277, memberId='consumer-foo-1-616e15eb-d512-4072-8323-930dcfd97dbd', protocol='range'}
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:28:19[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:28:54[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:28:54[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:28:54[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:29:58[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-13 17:29:58[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m14s309ms263µs900ns).
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:29:58[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=277, memberId='consumer-foo-1-616e15eb-d512-4072-8323-930dcfd97dbd', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=279, memberId='consumer-foo-1-43530860-3145-41ad-946e-13c761191969', protocol='range'}
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 279: {consumer-foo-1-43530860-3145-41ad-946e-13c761191969=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=279, memberId='consumer-foo-1-43530860-3145-41ad-946e-13c761191969', protocol='range'}
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-43530860-3145-41ad-946e-13c761191969 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:29:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:29:58[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:29:58[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:29:58[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:30:00[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 40384 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:30:00[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 41 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 146 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:30:01[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:30:02[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:30:02[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:30:02[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:30:02[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:30:03[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:30:03[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2634 ms
INFO  23-06-13 17:30:03[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:30:03[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:30:03[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:30:03[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:30:03[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:30:03[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:30:04[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:30:04[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:30:05[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:30:07[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:30:07[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:30:07[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:30:07[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645007876
INFO  23-06-13 17:30:07[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:30:07[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:30:07[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:30:08[main] [ApiApplication:61] - Started ApiApplication in 8.778 seconds (JVM running for 9.657)
INFO  23-06-13 17:30:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:30:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:30:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:30:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:30:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=281, memberId='consumer-foo-1-7a9f1320-d22d-47a2-861b-6f387452cc1e', protocol='range'}
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 281: {consumer-foo-1-7a9f1320-d22d-47a2-861b-6f387452cc1e=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=281, memberId='consumer-foo-1-7a9f1320-d22d-47a2-861b-6f387452cc1e', protocol='range'}
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:30:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:30:16[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:30:16[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:30:16[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 2 ms
WARN  23-06-13 17:31:41[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m37s820ms14µs200ns).
INFO  23-06-13 17:31:41[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=281, memberId='consumer-foo-1-7a9f1320-d22d-47a2-861b-6f387452cc1e', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=283, memberId='consumer-foo-1-b51c240c-dccb-4c50-b7ef-85da4dc693bd', protocol='range'}
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 283: {consumer-foo-1-b51c240c-dccb-4c50-b7ef-85da4dc693bd=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=283, memberId='consumer-foo-1-b51c240c-dccb-4c50-b7ef-85da4dc693bd', protocol='range'}
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:31:41[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:31:45[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:33:27[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-13 17:33:27[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m14s603ms283µs400ns).
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:33:27[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:33:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:33:27[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:33:27[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:33:27[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:33:29[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 41424 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:33:29[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 38 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 125 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:33:30[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:33:31[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:33:31[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:33:31[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:33:31[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:33:31[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:33:31[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2430 ms
INFO  23-06-13 17:33:32[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:33:32[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:33:32[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:33:32[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:33:32[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:33:32[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:33:33[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:33:33[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:33:34[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:33:36[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:33:36[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:33:36[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:33:36[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645216411
INFO  23-06-13 17:33:36[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:33:36[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:33:36[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:33:37[main] [ApiApplication:61] - Started ApiApplication in 8.014 seconds (JVM running for 8.906)
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=285, memberId='consumer-foo-1-5f5e575c-cf27-41ba-81c5-18479246ae7d', protocol='range'}
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 285: {consumer-foo-1-5f5e575c-cf27-41ba-81c5-18479246ae7d=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=285, memberId='consumer-foo-1-5f5e575c-cf27-41ba-81c5-18479246ae7d', protocol='range'}
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:33:37[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:33:43[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:33:43[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:33:43[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 1 ms
WARN  23-06-13 17:35:08[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m35s424ms176µs300ns).
INFO  23-06-13 17:35:08[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:35:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:35:08[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:35:09[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=285, memberId='consumer-foo-1-5f5e575c-cf27-41ba-81c5-18479246ae7d', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=287, memberId='consumer-foo-1-28f63d81-e7ac-48e5-b7f6-e8fb647dc7d7', protocol='range'}
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 287: {consumer-foo-1-28f63d81-e7ac-48e5-b7f6-e8fb647dc7d7=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=287, memberId='consumer-foo-1-28f63d81-e7ac-48e5-b7f6-e8fb647dc7d7', protocol='range'}
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:35:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-28f63d81-e7ac-48e5-b7f6-e8fb647dc7d7 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:35:14[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:35:14[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:35:14[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:35:14[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:35:16[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 27932 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:35:16[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 41 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 134 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:35:17[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 18 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:35:18[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:35:18[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:35:18[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:35:18[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:35:19[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:35:19[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2484 ms
INFO  23-06-13 17:35:19[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:35:19[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:35:19[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:35:19[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:35:19[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:35:19[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:35:20[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:35:20[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:35:21[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:35:23[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:35:23[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:35:23[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:35:23[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645323501
INFO  23-06-13 17:35:23[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:35:23[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:35:23[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:35:23[http-nio-8090-exec-5] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:35:23[http-nio-8090-exec-5] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:35:23[http-nio-8090-exec-5] [DispatcherServlet:547] - Completed initialization in 4 ms
WARN  23-06-13 17:37:01[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m41s226ms208µs101ns).
INFO  23-06-13 17:37:01[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "java.util.Optional.isPresent()" because "retrieveSnapshot" is null
INFO  23-06-13 17:37:01[main] [ApiApplication:61] - Started ApiApplication in 105.287 seconds (JVM running for 106.139)
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:37:01[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:37:01[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:37:01[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:37:01[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:37:03[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 39756 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:37:03[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 47 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 112 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:37:04[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 16 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:37:05[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:37:05[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:37:05[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:37:05[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:37:05[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:37:05[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2296 ms
INFO  23-06-13 17:37:05[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:37:05[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:37:06[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:37:06[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:37:06[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:37:06[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:37:07[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:37:07[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:37:07[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:37:09[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:37:10[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:37:10[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:37:10[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645430115
INFO  23-06-13 17:37:10[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:37:10[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:37:10[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:37:11[main] [ApiApplication:61] - Started ApiApplication in 8.142 seconds (JVM running for 8.913)
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=289, memberId='consumer-foo-1-ebe4dd4c-6bed-4432-9510-f66d7ecd8694', protocol='range'}
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 289: {consumer-foo-1-ebe4dd4c-6bed-4432-9510-f66d7ecd8694=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=289, memberId='consumer-foo-1-ebe4dd4c-6bed-4432-9510-f66d7ecd8694', protocol='range'}
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:37:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:37:14[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:37:14[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:37:14[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
WARN  23-06-13 17:37:14[http-nio-8090-exec-1] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:37:14[http-nio-8090-exec-1] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:37:14[http-nio-8090-exec-1] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:37:14[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:37:17[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 17:37:21[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
WARN  23-06-13 17:37:25[http-nio-8090-exec-5] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:37:25[http-nio-8090-exec-5] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:37:25[http-nio-8090-exec-5] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:37:25[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:38:01[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
WARN  23-06-13 17:38:10[http-nio-8090-exec-9] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:38:10[http-nio-8090-exec-9] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:38:10[http-nio-8090-exec-9] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:38:10[http-nio-8090-exec-9] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-ebe4dd4c-6bed-4432-9510-f66d7ecd8694 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:38:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:38:17[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:38:17[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:38:17[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:38:19[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 27976 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:38:19[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 46 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 114 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:38:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 18 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:38:21[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:38:21[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:38:21[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:38:21[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:38:21[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:38:21[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2534 ms
INFO  23-06-13 17:38:21[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:38:22[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:38:22[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:38:22[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:38:22[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:38:22[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:38:23[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:38:23[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:38:24[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:38:26[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:38:26[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:38:26[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:38:26[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645506282
INFO  23-06-13 17:38:26[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:38:26[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:38:26[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:38:26[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:38:26[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:38:26[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:38:27[main] [ApiApplication:61] - Started ApiApplication in 8.601 seconds (JVM running for 9.387)
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
WARN  23-06-13 17:38:27[http-nio-8090-exec-1] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:38:27[http-nio-8090-exec-1] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:38:27[http-nio-8090-exec-1] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:38:27[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=291, memberId='consumer-foo-1-39f96546-ae7f-4276-8d53-ab99efb9840f', protocol='range'}
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 291: {consumer-foo-1-39f96546-ae7f-4276-8d53-ab99efb9840f=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=291, memberId='consumer-foo-1-39f96546-ae7f-4276-8d53-ab99efb9840f', protocol='range'}
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:38:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:38:27[http-nio-8090-exec-2] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:38:27[http-nio-8090-exec-2] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:38:27[http-nio-8090-exec-2] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:38:27[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:40:26[http-nio-8090-exec-9] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
WARN  23-06-13 17:40:31[http-nio-8090-exec-10] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:40:31[http-nio-8090-exec-10] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:40:31[http-nio-8090-exec-10] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:40:31[http-nio-8090-exec-10] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
WARN  23-06-13 17:40:38[http-nio-8090-exec-8] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:40:38[http-nio-8090-exec-8] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:40:38[http-nio-8090-exec-8] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:40:38[http-nio-8090-exec-8] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:40:54[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-13 17:40:54[http-nio-8090-exec-7] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
ERROR 23-06-13 17:40:54[http-nio-8090-exec-7] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:40:54[http-nio-8090-exec-7] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:40:54[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=291, memberId='consumer-foo-1-39f96546-ae7f-4276-8d53-ab99efb9840f', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=293, memberId='consumer-foo-1-fdd1b017-b906-407f-a2e6-3260899dc8d9', protocol='range'}
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 293: {consumer-foo-1-fdd1b017-b906-407f-a2e6-3260899dc8d9=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=293, memberId='consumer-foo-1-fdd1b017-b906-407f-a2e6-3260899dc8d9', protocol='range'}
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:40:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:41:27[http-nio-8090-exec-6] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:41:27[http-nio-8090-exec-6] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:41:27[http-nio-8090-exec-6] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:41:27[http-nio-8090-exec-6] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
WARN  23-06-13 17:41:29[http-nio-8090-exec-5] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:41:29[http-nio-8090-exec-5] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:41:29[http-nio-8090-exec-5] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:41:29[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
WARN  23-06-13 17:41:58[http-nio-8090-exec-1] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:41:58[http-nio-8090-exec-1] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:41:58[http-nio-8090-exec-1] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:41:58[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:42:09[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-13 17:42:50[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-13 17:42:50[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=52s378ms164µs399ns).
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-13 17:42:50[http-nio-8090-exec-3] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:42:50[http-nio-8090-exec-3] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:42:50[http-nio-8090-exec-3] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:42:50[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=293, memberId='consumer-foo-1-fdd1b017-b906-407f-a2e6-3260899dc8d9', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=295, memberId='consumer-foo-1-0bdd4665-4de7-4bf2-b0f1-9d9553aa7f98', protocol='range'}
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 295: {consumer-foo-1-0bdd4665-4de7-4bf2-b0f1-9d9553aa7f98=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=295, memberId='consumer-foo-1-0bdd4665-4de7-4bf2-b0f1-9d9553aa7f98', protocol='range'}
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:42:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-0bdd4665-4de7-4bf2-b0f1-9d9553aa7f98 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:43:07[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:43:07[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:43:07[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:43:07[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:43:09[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 39640 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:43:09[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 44 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 98 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:10[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 21 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:43:11[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:43:11[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:43:11[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:43:11[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:43:11[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:43:11[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2366 ms
INFO  23-06-13 17:43:12[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:43:12[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:43:12[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:43:12[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:43:12[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:43:12[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:43:13[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:43:13[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:43:14[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:43:16[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:43:16[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:43:16[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:43:16[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645796259
INFO  23-06-13 17:43:16[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:43:16[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:43:17[main] [ApiApplication:61] - Started ApiApplication in 8.218 seconds (JVM running for 8.978)
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:43:17[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:43:17[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:43:17[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:43:17[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:43:19[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 37752 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:43:19[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 40 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 125 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:43:20[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:43:21[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:43:21[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:43:21[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:43:21[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:43:22[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:43:22[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2539 ms
INFO  23-06-13 17:43:22[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:43:22[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:43:22[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:43:22[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:43:22[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:43:22[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:43:23[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:43:23[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:43:24[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:43:26[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:43:26[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:43:26[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:43:26[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645806603
INFO  23-06-13 17:43:26[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:43:26[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:43:26[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:43:27[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:43:27[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:43:27[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:43:27[main] [ApiApplication:61] - Started ApiApplication in 8.524 seconds (JVM running for 9.349)
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=297, memberId='consumer-foo-1-a4d97162-0b50-4bc7-ad0f-873443c41601', protocol='range'}
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 297: {consumer-foo-1-a4d97162-0b50-4bc7-ad0f-873443c41601=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=297, memberId='consumer-foo-1-a4d97162-0b50-4bc7-ad0f-873443c41601', protocol='range'}
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:43:27[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:43:29[http-nio-8090-exec-2] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:43:29[http-nio-8090-exec-2] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:43:29[http-nio-8090-exec-2] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
INFO  23-06-13 17:43:29[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
WARN  23-06-13 17:43:54[http-nio-8090-exec-1] [SqlExceptionHelper:137] - SQL Error: 0, SQLState: 22001
ERROR 23-06-13 17:43:54[http-nio-8090-exec-1] [SqlExceptionHelper:142] - ERROR: value too long for type character varying(255)
INFO  23-06-13 17:43:54[http-nio-8090-exec-1] [AbstractBatchImpl:213] - HHH000010: On release of batch it still contained JDBC statements
WARN  23-06-13 17:45:11[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m18s771ms948µs400ns).
INFO  23-06-13 17:45:11[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
ERROR 23-06-13 17:45:11[http-nio-8090-exec-1] [CartEventStore:51] - could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.DataException: could not execute statement
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=297, memberId='consumer-foo-1-a4d97162-0b50-4bc7-ad0f-873443c41601', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=299, memberId='consumer-foo-1-963999c4-829b-43e4-a9b3-b3d314f269b1', protocol='range'}
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 299: {consumer-foo-1-963999c4-829b-43e4-a9b3-b3d314f269b1=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=299, memberId='consumer-foo-1-963999c4-829b-43e4-a9b3-b3d314f269b1', protocol='range'}
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:45:11[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:45:20[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 35000 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:45:20[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 39 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 127 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:45:21[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 17 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:45:22[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:45:22[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:45:22[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:45:22[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:45:23[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:45:23[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2513 ms
INFO  23-06-13 17:45:23[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:45:23[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:45:23[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:45:23[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:45:24[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:45:24[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:45:25[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:45:25[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:45:26[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:45:27[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:45:27[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:45:27[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:45:27[main] [AppInfoParser:121] - Kafka startTimeMs: 1686645927889
INFO  23-06-13 17:45:27[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:45:27[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:45:27[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:45:28[main] [ApiApplication:61] - Started ApiApplication in 8.616 seconds (JVM running for 9.391)
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=301, memberId='consumer-foo-1-d2b59a34-d785-4c0d-b883-2ade7324ce38', protocol='range'}
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 301: {consumer-foo-1-d2b59a34-d785-4c0d-b883-2ade7324ce38=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=301, memberId='consumer-foo-1-d2b59a34-d785-4c0d-b883-2ade7324ce38', protocol='range'}
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:45:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:45:53[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:45:53[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:45:53[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:46:10[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.Member.getMemberId()" because "readMember" is null
WARN  23-06-13 17:47:10[http-nio-8090-exec-9] [AbstractEventProjector:24] - null
java.lang.reflect.InvocationTargetException: null
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at web.api.eventSourcing.event.AbstractEventProjector.handle(AbstractEventProjector.java:21)
	at web.api.eventSourcing.event.CartEventStore.saveEvents(CartEventStore.java:55)
	at web.api.eventSourcing.event.CartEventStore$$FastClassBySpringCGLIB$$91beed65.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at web.api.eventSourcing.event.CartEventStore$$EnhancerBySpringCGLIB$$40a80f00.saveEvents(<generated>)
	at web.api.eventSourcing.event.AbstractEventHandler.save(AbstractEventHandler.java:83)
	at web.api.service.CartService.createCart(CartService.java:47)
	at web.api.controller.CartController.createOrder(CartController.java:28)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1071)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:964)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:696)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:779)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:177)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:891)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1784)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.lang.NullPointerException: Cannot invoke "web.api.eventSourcing.query.Cart.getSeq()" because "cart" is null
	at web.api.eventSourcing.event.CartEventProjector.execute(CartEventProjector.java:27)
	... 69 common frames omitted
WARN  23-06-13 17:48:15[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=50s514ms944µs899ns).
INFO  23-06-13 17:48:15[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:48:15[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=301, memberId='consumer-foo-1-d2b59a34-d785-4c0d-b883-2ade7324ce38', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=303, memberId='consumer-foo-1-ec4c5b3d-1222-4fba-8c78-1e6c58f106f9', protocol='range'}
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 303: {consumer-foo-1-ec4c5b3d-1222-4fba-8c78-1e6c58f106f9=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=303, memberId='consumer-foo-1-ec4c5b3d-1222-4fba-8c78-1e6c58f106f9', protocol='range'}
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:48:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:48:59[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:48:59[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [FetchSessionHandler:481] - [Consumer clientId=consumer-foo-1, groupId=foo] Error sending fetch request (sessionId=1812674819, epoch=264) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=303, memberId='consumer-foo-1-ec4c5b3d-1222-4fba-8c78-1e6c58f106f9', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=305, memberId='consumer-foo-1-685ef7c8-5372-4c47-b6ca-62b6f3160d62', protocol='range'}
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 305: {consumer-foo-1-685ef7c8-5372-4c47-b6ca-62b6f3160d62=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=305, memberId='consumer-foo-1-685ef7c8-5372-4c47-b6ca-62b6f3160d62', protocol='range'}
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:48:59[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:49:47[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-13 17:49:47[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=48s291ms303µs600ns).
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:49:47[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:49:47[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:49:47[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:49:47[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:49:54[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 44036 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:49:54[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 47 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:49:55[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 152 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:49:56[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 15 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:49:57[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:49:57[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:49:57[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:49:57[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:49:57[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:49:57[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2711 ms
INFO  23-06-13 17:49:58[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:49:58[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:49:58[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:49:58[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:49:58[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:49:58[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:49:59[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:49:59[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:50:00[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:50:02[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:50:02[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:50:02[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:50:02[main] [AppInfoParser:121] - Kafka startTimeMs: 1686646202230
INFO  23-06-13 17:50:02[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:50:02[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:50:02[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:50:02[main] [ApiApplication:61] - Started ApiApplication in 8.431 seconds (JVM running for 9.236)
INFO  23-06-13 17:50:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:50:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:50:02[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=307, memberId='consumer-foo-1-65a9a0d4-27f4-407f-9009-1a27d2f92dbd', protocol='range'}
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 307: {consumer-foo-1-65a9a0d4-27f4-407f-9009-1a27d2f92dbd=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=307, memberId='consumer-foo-1-65a9a0d4-27f4-407f-9009-1a27d2f92dbd', protocol='range'}
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:50:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-65a9a0d4-27f4-407f-9009-1a27d2f92dbd sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:52:06[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:52:06[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:52:06[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:52:06[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:52:08[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 22464 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:52:08[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 47 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 112 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:09[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 24 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:52:10[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:52:10[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:52:10[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:52:10[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:52:11[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:52:11[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2669 ms
INFO  23-06-13 17:52:11[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:52:11[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:52:11[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:52:12[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:52:12[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:52:12[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:52:13[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:52:13[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:52:14[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:52:15[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:52:15[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:52:15[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:52:15[main] [AppInfoParser:121] - Kafka startTimeMs: 1686646335637
INFO  23-06-13 17:52:15[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:52:15[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:52:15[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:52:16[main] [ApiApplication:61] - Started ApiApplication in 8.059 seconds (JVM running for 9.1)
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=309, memberId='consumer-foo-1-92f23ec7-b934-490d-a806-1cf7ca51e66d', protocol='range'}
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 309: {consumer-foo-1-92f23ec7-b934-490d-a806-1cf7ca51e66d=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=309, memberId='consumer-foo-1-92f23ec7-b934-490d-a806-1cf7ca51e66d', protocol='range'}
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:52:16[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:52:18[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:52:18[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:52:18[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:52:21[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = No property 'by' found for type 'Long'; Traversed path: Snapshot.seq
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-92f23ec7-b934-490d-a806-1cf7ca51e66d sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:52:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:52:43[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:52:43[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:52:43[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:52:45[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 5864 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:52:45[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 43 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 114 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:52:46[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:52:47[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 15 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:52:47[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:52:48[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:52:48[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:52:48[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:52:48[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:52:48[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2544 ms
INFO  23-06-13 17:52:48[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:52:48[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:52:49[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:52:49[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:52:49[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:52:49[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:52:50[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:52:50[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:52:51[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:52:52[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:52:52[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:52:52[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:52:52[main] [AppInfoParser:121] - Kafka startTimeMs: 1686646372981
INFO  23-06-13 17:52:52[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:52:53[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:52:53[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:52:53[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:52:53[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:52:53[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 2 ms
INFO  23-06-13 17:52:57[main] [ApiApplication:61] - Started ApiApplication in 11.569 seconds (JVM running for 12.584)
WARN  23-06-13 17:53:39[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=50s202ms964µs).
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=311, memberId='consumer-foo-1-76512d71-52c5-4c02-a057-fff825b5f79c', protocol='range'}
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 311: {consumer-foo-1-76512d71-52c5-4c02-a057-fff825b5f79c=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=311, memberId='consumer-foo-1-76512d71-52c5-4c02-a057-fff825b5f79c', protocol='range'}
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:53:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:53:41[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-76512d71-52c5-4c02-a057-fff825b5f79c sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:54:33[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:54:33[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:54:33[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:54:33[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:54:35[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 43704 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:54:35[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:54:35[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:54:35[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 39 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 105 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:54:36[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 30 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:54:37[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:54:37[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:54:37[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:54:37[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:54:37[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:54:37[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2515 ms
INFO  23-06-13 17:54:37[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:54:38[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:54:38[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:54:38[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:54:38[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:54:38[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:54:39[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:54:39[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:54:40[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:54:41[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:54:42[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:54:42[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:54:42[main] [AppInfoParser:121] - Kafka startTimeMs: 1686646482025
INFO  23-06-13 17:54:42[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:54:42[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:54:42[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:54:42[main] [ApiApplication:61] - Started ApiApplication in 8.137 seconds (JVM running for 8.928)
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=313, memberId='consumer-foo-1-886fec15-e8f6-4e19-bbac-550fc9a77920', protocol='range'}
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 313: {consumer-foo-1-886fec15-e8f6-4e19-bbac-550fc9a77920=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=313, memberId='consumer-foo-1-886fec15-e8f6-4e19-bbac-550fc9a77920', protocol='range'}
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:54:43[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:54:44[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:54:44[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:54:44[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-13 17:54:54[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:54:54[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=313, memberId='consumer-foo-1-886fec15-e8f6-4e19-bbac-550fc9a77920', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=315, memberId='consumer-foo-1-af5bb0fe-f8e8-4a1a-862b-bb55243dea46', protocol='range'}
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 315: {consumer-foo-1-af5bb0fe-f8e8-4a1a-862b-bb55243dea46=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=315, memberId='consumer-foo-1-af5bb0fe-f8e8-4a1a-862b-bb55243dea46', protocol='range'}
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:54:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
WARN  23-06-13 17:55:54[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m16s373ms105µs).
INFO  23-06-13 17:55:54[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:55:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:55:54[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-13 17:55:54[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Cannot invoke "web.api.domain.AggregateRoot.replay(java.util.List)" because "aggregateRoot" is null
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-13 17:55:55[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-13 17:55:55[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-13 17:55:55[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-13 17:55:55[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-13 17:55:56[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 24848 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-13 17:55:56[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 46 ms. Found 0 JDBC repository interfaces.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-13 17:55:57[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 134 ms. Found 5 JPA repository interfaces.
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-13 17:55:58[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 19 ms. Found 1 Redis repository interfaces.
INFO  23-06-13 17:55:59[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-13 17:55:59[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:55:59[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-13 17:55:59[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-13 17:55:59[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-13 17:55:59[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2555 ms
INFO  23-06-13 17:55:59[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-13 17:55:59[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-13 17:56:00[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-13 17:56:00[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-13 17:56:00[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-13 17:56:00[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-13 17:56:01[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-13 17:56:01[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-13 17:56:02[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-13 17:56:03[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-13 17:56:03[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-13 17:56:03[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-13 17:56:03[main] [AppInfoParser:121] - Kafka startTimeMs: 1686646563852
INFO  23-06-13 17:56:03[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-13 17:56:03[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-13 17:56:03[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-13 17:56:04[main] [ApiApplication:61] - Started ApiApplication in 8.234 seconds (JVM running for 9.076)
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=317, memberId='consumer-foo-1-b769ae80-cbd9-4313-910a-449fac1972ce', protocol='range'}
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 317: {consumer-foo-1-b769ae80-cbd9-4313-910a-449fac1972ce=Assignment(partitions=[my1-topic-0])}
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=317, memberId='consumer-foo-1-b769ae80-cbd9-4313-910a-449fac1972ce', protocol='range'}
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-13 17:56:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-13 17:56:06[http-nio-8090-exec-2] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-13 17:56:06[http-nio-8090-exec-2] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-13 17:56:06[http-nio-8090-exec-2] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-14 08:35:31[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 13728 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-14 08:35:31[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 42 ms. Found 0 JDBC repository interfaces.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 158 ms. Found 5 JPA repository interfaces.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 08:35:32[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 16 ms. Found 1 Redis repository interfaces.
INFO  23-06-14 08:35:33[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-14 08:35:33[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-14 08:35:33[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-14 08:35:33[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-14 08:35:34[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-14 08:35:34[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2691 ms
INFO  23-06-14 08:35:34[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-14 08:35:34[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-14 08:35:34[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-14 08:35:35[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-14 08:35:35[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-14 08:35:35[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-14 08:35:36[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-14 08:35:36[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-14 08:35:37[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-14 08:35:38[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-14 08:35:38[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-14 08:35:38[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-14 08:35:38[main] [AppInfoParser:121] - Kafka startTimeMs: 1686699338757
INFO  23-06-14 08:35:38[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-14 08:35:38[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-14 08:35:38[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-14 08:35:39[main] [ApiApplication:61] - Started ApiApplication in 8.195 seconds (JVM running for 8.974)
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=321, memberId='consumer-foo-1-f1315b24-e0e3-4a77-81d9-a2ddb1a8d90b', protocol='range'}
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 321: {consumer-foo-1-f1315b24-e0e3-4a77-81d9-a2ddb1a8d90b=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=321, memberId='consumer-foo-1-f1315b24-e0e3-4a77-81d9-a2ddb1a8d90b', protocol='range'}
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 08:35:39[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 08:35:52[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-14 08:35:52[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-14 08:35:52[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 1 ms
INFO  23-06-14 08:36:08[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=321, memberId='consumer-foo-1-f1315b24-e0e3-4a77-81d9-a2ddb1a8d90b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=323, memberId='consumer-foo-1-d57b08f3-ef3f-43bb-a1a9-23ecfb3ae8d1', protocol='range'}
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 323: {consumer-foo-1-d57b08f3-ef3f-43bb-a1a9-23ecfb3ae8d1=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=323, memberId='consumer-foo-1-d57b08f3-ef3f-43bb-a1a9-23ecfb3ae8d1', protocol='range'}
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 08:36:13[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 08:36:44[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=323, memberId='consumer-foo-1-d57b08f3-ef3f-43bb-a1a9-23ecfb3ae8d1', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=325, memberId='consumer-foo-1-8ba20d01-6a22-4d29-8b88-f7ce2d213918', protocol='range'}
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 325: {consumer-foo-1-8ba20d01-6a22-4d29-8b88-f7ce2d213918=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=325, memberId='consumer-foo-1-8ba20d01-6a22-4d29-8b88-f7ce2d213918', protocol='range'}
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 08:36:45[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 10:37:09[http-nio-8090-exec-5] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 10:48:39[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
WARN  23-06-14 10:48:39[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=51s702ms458µs501ns).
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=325, memberId='consumer-foo-1-8ba20d01-6a22-4d29-8b88-f7ce2d213918', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=327, memberId='consumer-foo-1-82e6d368-4bf8-42ca-bf79-0287d8daffad', protocol='range'}
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 327: {consumer-foo-1-82e6d368-4bf8-42ca-bf79-0287d8daffad=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=327, memberId='consumer-foo-1-82e6d368-4bf8-42ca-bf79-0287d8daffad', protocol='range'}
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 10:48:40[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 10:49:48[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 10:49:48[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [FetchSessionHandler:481] - [Consumer clientId=consumer-foo-1, groupId=foo] Error sending fetch request (sessionId=1463120803, epoch=15708) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
INFO  23-06-14 10:49:50[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=327, memberId='consumer-foo-1-82e6d368-4bf8-42ca-bf79-0287d8daffad', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=329, memberId='consumer-foo-1-1ddeecfb-2c79-4df2-b865-5db8ec11c544', protocol='range'}
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 329: {consumer-foo-1-1ddeecfb-2c79-4df2-b865-5db8ec11c544=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=329, memberId='consumer-foo-1-1ddeecfb-2c79-4df2-b865-5db8ec11c544', protocol='range'}
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 10:49:51[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 10:51:45[http-nio-8090-exec-8] [ExceptHandler:43] - ExceptHandler.commonException = No value present
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-1ddeecfb-2c79-4df2-b865-5db8ec11c544 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-14 10:55:15[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-14 10:55:15[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-14 10:55:15[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-14 10:55:15[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
INFO  23-06-14 10:55:17[main] [ApiApplication:55] - Starting ApiApplication using Java 17.0.3 on limdoyoung with PID 39588 (C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample\target\classes started by dlaeh in C:\Users\dlaeh\workSpaces\spring-event-sourcing-sample)
INFO  23-06-14 10:55:17[main] [ApiApplication:631] - No active profile set, falling back to 1 default profile: "default"
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JDBC repositories in DEFAULT mode.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JDBC - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JDBC repository, consider annotating your entities with one of these annotations: org.springframework.data.relational.core.mapping.Table.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 37 ms. Found 0 JDBC repository interfaces.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data JPA - Could not safely identify store assignment for repository candidate interface web.api.repository.SnapshotRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: javax.persistence.Entity, javax.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 104 ms. Found 5 JPA repository interfaces.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:262] - Multiple Spring Data modules found, entering strict repository configuration mode
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:132] - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.eventSourcing.event.EventStore; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartItemRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.CartRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.EventStoreRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.MemberJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationExtensionSupport:349] - Spring Data Redis - Could not safely identify store assignment for repository candidate interface web.api.repository.ProductJpaRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
INFO  23-06-14 10:55:18[main] [RepositoryConfigurationDelegate:201] - Finished Spring Data repository scanning in 16 ms. Found 1 Redis repository interfaces.
INFO  23-06-14 10:55:19[main] [TomcatWebServer:108] - Tomcat initialized with port(s): 8090 (http)
INFO  23-06-14 10:55:19[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8090"]
INFO  23-06-14 10:55:19[main] [StandardService:173] - Starting service [Tomcat]
INFO  23-06-14 10:55:19[main] [StandardEngine:173] - Starting Servlet engine: [Apache Tomcat/9.0.71]
INFO  23-06-14 10:55:19[main] [[/]:173] - Initializing Spring embedded WebApplicationContext
INFO  23-06-14 10:55:19[main] [ServletWebServerApplicationContext:292] - Root WebApplicationContext: initialization completed in 2481 ms
INFO  23-06-14 10:55:20[main] [LogHelper:31] - HHH000204: Processing PersistenceUnitInfo [name: default]
INFO  23-06-14 10:55:20[main] [Version:44] - HHH000412: Hibernate ORM core version 5.6.15.Final
INFO  23-06-14 10:55:20[main] [Version:56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
INFO  23-06-14 10:55:20[main] [HikariDataSource:110] - HikariPool-1 - Starting...
INFO  23-06-14 10:55:20[main] [HikariDataSource:123] - HikariPool-1 - Start completed.
INFO  23-06-14 10:55:20[main] [Dialect:175] - HHH000400: Using dialect: org.hibernate.dialect.PostgreSQL10Dialect
INFO  23-06-14 10:55:21[main] [JtaPlatformInitiator:52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
INFO  23-06-14 10:55:21[main] [LocalContainerEntityManagerFactoryBean:437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
WARN  23-06-14 10:55:22[main] [JpaBaseConfiguration$JpaWebConfiguration:223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
INFO  23-06-14 10:55:24[main] [ConsumerConfig:361] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-foo-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = foo
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  23-06-14 10:55:24[main] [AppInfoParser:119] - Kafka version: 2.7.0
INFO  23-06-14 10:55:24[main] [AppInfoParser:120] - Kafka commitId: 448719dc99a19793
INFO  23-06-14 10:55:24[main] [AppInfoParser:121] - Kafka startTimeMs: 1686707724299
INFO  23-06-14 10:55:24[main] [KafkaConsumer:961] - [Consumer clientId=consumer-foo-1, groupId=foo] Subscribed to topic(s): my1-topic
INFO  23-06-14 10:55:24[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8090"]
INFO  23-06-14 10:55:24[main] [TomcatWebServer:220] - Tomcat started on port(s): 8090 (http) with context path ''
INFO  23-06-14 10:55:25[main] [ApiApplication:61] - Started ApiApplication in 8.313 seconds (JVM running for 9.118)
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metadata:279] - [Consumer clientId=consumer-foo-1, groupId=foo] Cluster ID: sHUSsb60QyipALfy4nRqJw
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=331, memberId='consumer-foo-1-59d4c567-f0ef-403c-b334-87f8eff1fac7', protocol='range'}
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 331: {consumer-foo-1-59d4c567-f0ef-403c-b334-87f8eff1fac7=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=331, memberId='consumer-foo-1-59d4c567-f0ef-403c-b334-87f8eff1fac7', protocol='range'}
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 10:55:25[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 10:55:47[http-nio-8090-exec-1] [[/]:173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  23-06-14 10:55:47[http-nio-8090-exec-1] [DispatcherServlet:525] - Initializing Servlet 'dispatcherServlet'
INFO  23-06-14 10:55:47[http-nio-8090-exec-1] [DispatcherServlet:547] - Completed initialization in 0 ms
INFO  23-06-14 10:56:16[http-nio-8090-exec-2] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
WARN  23-06-14 10:56:24[http-nio-8090-exec-3] [AbstractEventProjector:24] - null
java.lang.reflect.InvocationTargetException: null
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at web.api.eventSourcing.event.AbstractEventProjector.handle(AbstractEventProjector.java:21)
	at web.api.eventSourcing.event.CartEventStore.saveEvents(CartEventStore.java:55)
	at web.api.eventSourcing.event.CartEventStore$$FastClassBySpringCGLIB$$91beed65.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at web.api.eventSourcing.event.CartEventStore$$EnhancerBySpringCGLIB$$baeabc69.saveEvents(<generated>)
	at web.api.eventSourcing.event.AbstractEventHandler.save(AbstractEventHandler.java:83)
	at web.api.service.CartService.createCart(CartService.java:48)
	at web.api.controller.CartController.createOrder(CartController.java:29)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1071)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:964)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:696)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:779)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:177)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:891)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1784)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.lang.NullPointerException: Cannot invoke "web.api.eventSourcing.query.Cart.getSeq()" because "cart" is null
	at web.api.eventSourcing.event.CartEventProjector.execute(CartEventProjector.java:27)
	... 69 common frames omitted
INFO  23-06-14 10:56:52[http-nio-8090-exec-6] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 10:57:18[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 10:58:55[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 10:58:58[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 10:59:00[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=331, memberId='consumer-foo-1-59d4c567-f0ef-403c-b334-87f8eff1fac7', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=333, memberId='consumer-foo-1-096b2a2b-cfe6-4219-8100-242d77a0deff', protocol='range'}
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 333: {consumer-foo-1-096b2a2b-cfe6-4219-8100-242d77a0deff=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=333, memberId='consumer-foo-1-096b2a2b-cfe6-4219-8100-242d77a0deff', protocol='range'}
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 10:59:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 10:59:26[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 10:59:32[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 10:59:32[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=333, memberId='consumer-foo-1-096b2a2b-cfe6-4219-8100-242d77a0deff', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 10:59:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 10:59:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 10:59:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 10:59:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 10:59:34[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 11:00:05[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:611] - [Consumer clientId=consumer-foo-1, groupId=foo] JoinGroup failed: The coordinator is not aware of this member. Need to re-join the group. Sent generation was Generation{generationId=-1, memberId='consumer-foo-1-886cc697-ee0e-4c3a-b425-75178a572ef7', protocol='null'}
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:472] - [Consumer clientId=consumer-foo-1, groupId=foo] Rebalance failed.
org.apache.kafka.common.errors.UnknownMemberIdException: The coordinator is not aware of this member.
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=335, memberId='consumer-foo-1-2a807f2a-f278-4bd9-8834-30f31be122fb', protocol='range'}
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 335: {consumer-foo-1-2a807f2a-f278-4bd9-8834-30f31be122fb=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=335, memberId='consumer-foo-1-2a807f2a-f278-4bd9-8834-30f31be122fb', protocol='range'}
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 11:00:09[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 12:10:03[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
INFO  23-06-14 12:10:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 12:10:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 12:10:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-14 12:10:33[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=46m56s846ms657µs100ns).
WARN  23-06-14 13:16:26[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m22s559ms902µs700ns).
INFO  23-06-14 13:16:26[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 13:16:26[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=335, memberId='consumer-foo-1-2a807f2a-f278-4bd9-8834-30f31be122fb', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=337, memberId='consumer-foo-1-f6d67ea0-81c2-47b6-8c31-5a16e82ec3bc', protocol='range'}
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 337: {consumer-foo-1-f6d67ea0-81c2-47b6-8c31-5a16e82ec3bc=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=337, memberId='consumer-foo-1-f6d67ea0-81c2-47b6-8c31-5a16e82ec3bc', protocol='range'}
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 13:16:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 14:32:00[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 14:32:00[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-14 14:32:16[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=2m49s336ms832µs900ns).
INFO  23-06-14 14:58:31[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
INFO  23-06-14 14:58:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 14:58:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 14:58:31[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-14 14:58:42[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=17m25s94ms333µs).
INFO  23-06-14 15:17:12[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 15:17:12[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 15:17:12[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 15:17:12[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-14 15:17:32[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=7m20s270ms618µs800ns).
INFO  23-06-14 15:28:44[http-nio-8090-exec-3] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 15:29:34[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 15:30:48[http-nio-8090-exec-9] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 15:30:50[http-nio-8090-exec-10] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 15:30:50[http-nio-8090-exec-1] [ExceptHandler:43] - ExceptHandler.commonException = Unmatched Version : expected: {}, actual: {}; nested exception is java.lang.IllegalStateException: Unmatched Version : expected: {}, actual: {}
INFO  23-06-14 15:32:03[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 15:32:03[http-nio-8090-exec-7] [ExceptHandler:43] - ExceptHandler.commonException = No value present
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1121] - [Consumer clientId=consumer-foo-1, groupId=foo] Attempt to heartbeat with Generation{generationId=337, memberId='consumer-foo-1-f6d67ea0-81c2-47b6-8c31-5a16e82ec3bc', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:691] - [Consumer clientId=consumer-foo-1, groupId=foo] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:326] - [Consumer clientId=consumer-foo-1, groupId=foo] Lost previously assigned partitions my1-topic-0
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions lost: [my1-topic-0]
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:540] - [Consumer clientId=consumer-foo-1, groupId=foo] (Re-)joining group
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:596] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully joined group with generation Generation{generationId=339, memberId='consumer-foo-1-07a0f860-2ba4-4e6d-acf5-3152ecf0107b', protocol='range'}
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:626] - [Consumer clientId=consumer-foo-1, groupId=foo] Finished assignment for group at generation 339: {consumer-foo-1-07a0f860-2ba4-4e6d-acf5-3152ecf0107b=Assignment(partitions=[my1-topic-0])}
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:756] - [Consumer clientId=consumer-foo-1, groupId=foo] Successfully synced group in generation Generation{generationId=339, memberId='consumer-foo-1-07a0f860-2ba4-4e6d-acf5-3152ecf0107b', protocol='range'}
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:276] - [Consumer clientId=consumer-foo-1, groupId=foo] Notifying assignor about the new Assignment(partitions=[my1-topic-0])
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:288] - [Consumer clientId=consumer-foo-1, groupId=foo] Adding newly assigned partitions: my1-topic-0
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:820] - [Consumer clientId=consumer-foo-1, groupId=foo] Setting offset for partition my1-topic-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
INFO  23-06-14 15:32:03[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions assigned: [my1-topic-0]
INFO  23-06-14 15:32:07[http-nio-8090-exec-8] [ExceptHandler:43] - ExceptHandler.commonException = No value present
INFO  23-06-14 15:32:27[http-nio-8090-exec-10] [ExceptHandler:43] - ExceptHandler.commonException = No value present
INFO  23-06-14 15:37:30[kafka-coordinator-heartbeat-thread | foo] [AbstractCoordinator:904] - [Consumer clientId=consumer-foo-1, groupId=foo] Group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
INFO  23-06-14 15:37:30[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:847] - [Consumer clientId=consumer-foo-1, groupId=foo] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
WARN  23-06-14 15:37:44[HikariPool-1 housekeeper] [HikariPool:788] - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=2m41s81ms36µs500ns).
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [ConsumerCoordinator:307] - [Consumer clientId=consumer-foo-1, groupId=foo] Revoke previously assigned partitions my1-topic-0
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: partitions revoked: [my1-topic-0]
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AbstractCoordinator:1029] - [Consumer clientId=consumer-foo-1, groupId=foo] Member consumer-foo-1-07a0f860-2ba4-4e6d-acf5-3152ecf0107b sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaConsumer:1070] - [Consumer clientId=consumer-foo-1, groupId=foo] Unsubscribed all topics or patterns and assigned partitions
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:668] - Metrics scheduler closed
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:672] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Metrics:678] - Metrics reporters closed
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [AppInfoParser:83] - App info kafka.consumer for consumer-foo-1 unregistered
INFO  23-06-14 15:39:29[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [KafkaMessageListenerContainer:292] - foo: Consumer stopped
INFO  23-06-14 15:39:29[SpringApplicationShutdownHook] [LocalContainerEntityManagerFactoryBean:651] - Closing JPA EntityManagerFactory for persistence unit 'default'
INFO  23-06-14 15:39:29[SpringApplicationShutdownHook] [HikariDataSource:350] - HikariPool-1 - Shutdown initiated...
INFO  23-06-14 15:39:29[SpringApplicationShutdownHook] [HikariDataSource:352] - HikariPool-1 - Shutdown completed.
